{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, we will load m2c2kit data exported from our MongoDB collection titled `warehouse`, parse it into individual task dataframes, deduplicate and score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install m2c2-datakit\n",
    "!pip3 install m2c2-datakit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import M2C2 DataKit Library (it imports other libraries BTS...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import m2c2_datakit as m2c2\n",
    "m2c2.core.utils.get_package_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamp for saving files\n",
    "ts_fn = m2c2.core.utils.get_filename_timestamp()\n",
    "print(ts_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for Scoring\n",
    "\n",
    "To be specified in a task-specific way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical grouping for aggregation (can be edited)\n",
    "grouping_for_aggregation = [\"participant_id\", \"session_uuid\", \"session_id\"]\n",
    "\n",
    "# expected trials (will be different per task)\n",
    "trials_expected = 20\n",
    "\n",
    "# ontology for data filtering\n",
    "rt_outlier_low = 500\n",
    "rt_outlier_high = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Parse Data\n",
    "\n",
    "Eventually we will have various data loaders\n",
    "\n",
    "- mongodb_export - from Nelson (what we have now)\n",
    "- api_export - from backend API\n",
    "- metricwire_export - from MW portal\n",
    "- metricwire_api_export - from MW API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Full JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON data\n",
    "df, grouped_dataframes, validation, activity_names = m2c2.loaders.mongodb.load_mongodb_export('../data/production-mongo-export/data_exported_120424_1010am.json')\n",
    "\n",
    "# or folder of files from Metricwire Portal export (as of December 2024)\n",
    "#df, grouped_dataframes, validation, activity_names = m2c2.loaders.metricwire.load_metricwire_export(filepath = \"../../data/metricwire/unzipped/*/*/*.json\")\n",
    "\n",
    "print(f\"Validation was successful: {validation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Tasks of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `df_symbol_search_raw` and `df_grid_memory_raw` is going to be identical to what the new API returns in its JSON return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbol_search_raw = grouped_dataframes.get('Symbol Search')\n",
    "df_grid_memory_raw = grouped_dataframes.get('Grid Memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates, and Make JSON Data Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbol_search_unnested_dedup = m2c2.core.parse.unnest_trial_level_data(df_symbol_search_raw, drop_duplicates=True)\n",
    "df_grid_memory_unnested_dedup = m2c2.core.parse.unnest_trial_level_data(df_grid_memory_raw, drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Data\n",
    "* If from metricwire, can run raw\n",
    "* If production server run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbol_search_scored = m2c2.tasks.symbol_search.score_trials(df_symbol_search_unnested_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_memory_scored = m2c2.tasks.grid_memory.score_trials(df_grid_memory_unnested_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scores\n",
    "# custom_scores = [\n",
    "#     (\"custom_metric_1\", my_custom_func_1),\n",
    "#     (\"custom_metric_2\", my_custom_func_2),\n",
    "# ]\n",
    "\n",
    "# df_grid_memory_scored_custom = m2c2.tasks.grid_memory.score_grid_memory_data(df_grid_memory_unnested_dedup, \n",
    "#                                                                              scoring_funcs=custom_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic summary function (i.e., group by each participant and calculate summary statistics)\n",
    "df_symbol_search_summary = m2c2.core.scoring.summarize_data(\n",
    "                                        # primary arguments\n",
    "                                        df=df_symbol_search_scored, \n",
    "                                        grouping=grouping_for_aggregation, \n",
    "                                        summarization_func=m2c2.tasks.symbol_search.summarize, \n",
    "                                        \n",
    "                                        # additional arguments\n",
    "                                        trials_expected=20)\n",
    "df_symbol_search_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic summary function (i.e., group by each participant and calculate summary statistics)\n",
    "df_grid_memory_summary = m2c2.core.scoring.summarize_data(\n",
    "                                        # primary arguments\n",
    "                                        df=df_grid_memory_scored, \n",
    "                                        grouping=grouping_for_aggregation, \n",
    "                                        summarization_func=m2c2.tasks.grid_memory.summarize, \n",
    "                                        \n",
    "                                        # additional arguments\n",
    "                                        trials_expected=4)\n",
    "df_grid_memory_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbol_search_filt = df_symbol_search_scored.copy()\n",
    "df_symbol_search_filt = df_symbol_search_filt[['response_time_duration_ms', 'metric_accuracy']]\n",
    "m2c2.core.plot.plot_distribution(df_symbol_search_filt) #main_vars=True, exp_vars=False)\n",
    "\n",
    "df_grid_memory_filt = df_grid_memory_scored.copy()\n",
    "df_grid_memory_filt = df_grid_memory_filt[['metric_error_distance_mean', 'metric_error_distance_sum', 'metric_error_distance_hausdorff']]\n",
    "m2c2.core.plot.plot_distribution(df_grid_memory_filt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframes for Symbol Search\n",
    "m2c2.core.export.export_dataframe(df_symbol_search_raw, \n",
    "    f\"../output/m2c2_datakit_symbol_search_raw_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_symbol_search_unnested_dedup, \n",
    "    f\"../output/m2c2_datakit_symbol_search_unnested_dedup_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_symbol_search_scored, \n",
    "    f\"../output/m2c2_datakit_symbol_search_scored_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_symbol_search_summary, \n",
    "    f\"../output/m2c2_datakit_symbol_search_summary_{ts_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframes for Grid Memory\n",
    "m2c2.core.export.export_dataframe(df_grid_memory_raw, \n",
    "    f\"../output/m2c2_datakit_grid_memory_raw_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_grid_memory_unnested_dedup, \n",
    "    f\"../output/m2c2_datakit_grid_memory_unnested_dedup_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_grid_memory_scored, \n",
    "    f\"../output/m2c2_datakit_grid_memory_scored_{ts_fn}\")\n",
    "m2c2.core.export.export_dataframe(df_grid_memory_summary, \n",
    "    f\"../output/m2c2_datakit_grid_memory_summary_{ts_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
